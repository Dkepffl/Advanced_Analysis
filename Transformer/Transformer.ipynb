{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "8w_8koWBa6G7",
        "SJJSOhykbFbu",
        "AuRMuYteYppp",
        "qhsbaa7nn0Vu",
        "DjLRqsadRSVv",
        "1c9YUo0mn-t2",
        "IeXo-hitgJFk",
        "sJBlibJSoGRH",
        "hdljDJlGp0kl",
        "wkhuFLZkoTeV",
        "nKLxEC8AoYr6",
        "lOo3enKnofCX",
        "CAL6MuaJor6Y",
        "dSbaprIROaz-",
        "V-tjSzjBmve3"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO3IJZMZoCjoKPgOnwOoZcV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dkepffl/Advanced_Analysis/blob/main/Transformer/Transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Import Packages**"
      ],
      "metadata": {
        "id": "8w_8koWBa6G7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import CIFAR100\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "-OTuX_9EbES5"
      },
      "execution_count": 609,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data loader**"
      ],
      "metadata": {
        "id": "SJJSOhykbFbu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data loader\n",
        "path = './datasets/'\n",
        "\n",
        "# Data transform Setting\n",
        "transform = transforms.Compose([transforms.ToTensor()]) # Tensor 변환. 다른 전처리X\n",
        "\n",
        "# Load data\n",
        "train_data = CIFAR100(root=path,train=True,transform=transform,download=True)\n",
        "test_data = CIFAR100(root=path,train=False,transform=transform,download=True)\n",
        "\n",
        "batch_size = 100\n",
        "\n",
        "train_loader = DataLoader(dataset=train_data,batch_size=batch_size,shuffle=True,num_workers=0)\n",
        "test_loader = DataLoader(dataset=test_data,batch_size=batch_size,shuffle=False,num_workers=0)"
      ],
      "metadata": {
        "id": "s_iY1Eo3bNlx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42244b54-6e20-4706-dc2e-77473bdca35c"
      },
      "execution_count": 610,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Image 확인용**"
      ],
      "metadata": {
        "id": "AuRMuYteYppp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(42)\n",
        "random_nums = [np.random.randint(1, 2001) for i in range(5)]\n",
        "\n",
        "plt.figure(figsize=(10, 2))\n",
        "\n",
        "for i in range(len(random_nums)):\n",
        "    plt.subplot(1, 5, i+1) # 5번 번갈아가며 서브플롯 생성\n",
        "    y = train_loader.dataset[random_nums[i]][0]\n",
        "    plt.imshow(np.transpose(y, (1,2,0))) # 이미지 데이터를 (C, H, W)에서 (H, W, C) 차원으로 변환, 랜덤 번호의 이미지 출력\n",
        "    plt.title(train_data.classes[train_loader.dataset[random_nums[i]][1]])\n",
        "    plt.axis('off')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "f00QrmXXXhJY",
        "outputId": "16166f20-5e56-4fb2-8f9c-bc10839e19bd"
      },
      "execution_count": 643,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x200 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Data shape**"
      ],
      "metadata": {
        "id": "1YX3R62yXpwk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = train_data[0][0].shape # 출력 결과 : [3, 32, 32]\n",
        "output_shape = len(train_data.classes) # 출력 결과 : 100"
      ],
      "metadata": {
        "id": "XWjsTu3dlKcI"
      },
      "execution_count": 612,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Transformer 구현**"
      ],
      "metadata": {
        "id": "QM2IkmKdlYfM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##########################################\n",
        "#### there is nothing to do upto here ####\n",
        "##########################################"
      ],
      "metadata": {
        "id": "i41zWBTWbOie"
      },
      "execution_count": 613,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Positional Encoding**\n",
        "```python\n",
        "# argument 정리\n",
        "pe = PositionalEncoding(device, max_len, d_model)\n",
        "pos_emb = pe(x)\n",
        "```\n",
        "[Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, and Yann N. Dauphin. Convolu\n",
        "tional sequence to sequence learning. arXiv preprint arXiv:1705.03122v2, 2017.](https://arxiv.org/pdf/1705.03122)"
      ],
      "metadata": {
        "id": "qhsbaa7nn0Vu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# refer to Section 3.5 in the paper\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, device, max_len=512, d_model=16):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "        # max_len만큼 만들고 x의 seq_len만큼 잘라서 사용\n",
        "        self.pos_enc = torch.zeros(max_len, d_model,requires_grad=False, device=device)\n",
        "\n",
        "        # Position Encoding Matrix\n",
        "        pos = torch.arange(0, max_len, dtype=torch.float).unsqueeze(-1) # unsqueeze :->(max_len,1)\n",
        "        ii = torch.arange(0, d_model, step=2, dtype=torch.float) # 2i. (1, self.d_model)\n",
        "\n",
        "        '''\n",
        "        논문을 그대로 따르려면\n",
        "        i = torch.arange(0, self.d_model//2, step=1, dtype=torch.float)\n",
        "\n",
        "        self.pos_enc[:,0::2] = torch.sin(pos/(10000**((2*i)/d_model)))\n",
        "        self.pos_enc[:,1::2] = torch.cos(pos/(10000**((2*i)/d_model)))\n",
        "\n",
        "        torch.arange() 메서드 안에서 self.d_model//2 계산하는 것이 싫어서 아예 2i를 generate\n",
        "        -> O(n)이 다른가?\n",
        "        -> 반복문으로 해도 될 듯\n",
        "        '''\n",
        "        self.pos_enc[:,0::2] = torch.sin(pos/(10000**(ii/d_model)))\n",
        "        self.pos_enc[:,1::2] = torch.cos(pos/(10000**(ii/d_model)))\n",
        "\n",
        "        self.pos_enc.unsqueeze_(0) # [1, max_len, d_model]\n",
        "\n",
        "    def forward(self,x):\n",
        "        \"\"\"\n",
        "        x: transformed input embedding where x.shape = [batch_size, seq_len, data_dim]\n",
        "        \"\"\"\n",
        "        seq_len = x.shape[1]\n",
        "        pos_emb = self.pos_enc[:,:seq_len,:]\n",
        "\n",
        "        ''' for Debugging\n",
        "        print(x.shape) # torch.Size([100, 512, 3]) -> input linear transformation 빠져서 그랬음\n",
        "        print(pos_emb.shape) # torch.Size([1, 512, 16])\n",
        "        '''\n",
        "\n",
        "        return pos_emb"
      ],
      "metadata": {
        "id": "hH8H_dWbn8lm"
      },
      "execution_count": 614,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **idea**"
      ],
      "metadata": {
        "id": "DjLRqsadRSVv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To make Position Encoding Matrix\n",
        "temp = torch.zeros(4,4,requires_grad=False)\n",
        "\n",
        "temp2 = torch.arange(4).unsqueeze(-1) # row == pos\n",
        "temp3 = torch.arange(0, 4//2, 1) # column == i\n",
        "\n",
        "temp[:,0::2] = torch.sin(temp2/(10000**((2*temp3)/4)))\n",
        "temp[:,1::2] = torch.cos(temp2/(10000**((2*temp3)/4)))\n",
        "\n",
        "temp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyxUQ5xnMWux",
        "outputId": "2e4f3902-05dd-493c-fa1e-49699a91b22e"
      },
      "execution_count": 615,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  1.0000,  0.0000,  1.0000],\n",
              "        [ 0.8415,  0.5403,  0.0100,  0.9999],\n",
              "        [ 0.9093, -0.4161,  0.0200,  0.9998],\n",
              "        [ 0.1411, -0.9900,  0.0300,  0.9996]])"
            ]
          },
          "metadata": {},
          "execution_count": 615
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- matrix 모양이 좀 이상함...."
      ],
      "metadata": {
        "id": "fjqGQaNg5jLu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.arange(4).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K04VsRg44OS3",
        "outputId": "d1377507-4fd6-4bd4-ad90-ab43010f332b"
      },
      "execution_count": 616,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4])"
            ]
          },
          "metadata": {},
          "execution_count": 616
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.arange(4).unsqueeze(-1).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TObPeU175NWz",
        "outputId": "3618b1b5-418c-4317-8eea-ef41be89f53a"
      },
      "execution_count": 617,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 617
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Version 2\n",
        "temp = torch.zeros(4,4,requires_grad=False)\n",
        "\n",
        "temp2 = torch.arange(4).unsqueeze(-1,) # row == pos\n",
        "temp3 = torch.arange(0, 4, 2) # column == 2*i\n",
        "\n",
        "temp[:,0::2] = torch.sin(temp2/(10000**((temp3)/4)))\n",
        "temp[:,1::2] = torch.cos(temp2/(10000**((temp3)/4)))\n",
        "\n",
        "temp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWEfsHiFVUCf",
        "outputId": "5892e9fb-f2dc-47fb-c278-decf4f93e9bf"
      },
      "execution_count": 618,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0000,  1.0000,  0.0000,  1.0000],\n",
              "        [ 0.8415,  0.5403,  0.0100,  0.9999],\n",
              "        [ 0.9093, -0.4161,  0.0200,  0.9998],\n",
              "        [ 0.1411, -0.9900,  0.0300,  0.9996]])"
            ]
          },
          "metadata": {},
          "execution_count": 618
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "두 코드 결과 동일"
      ],
      "metadata": {
        "id": "2PddcDmsYvRH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **ScaledDotProductAttention**\n",
        "$$Attention(Q, K, V) = softmax(\\frac{QK^{T}}{\\sqrt {d_{k}}})V$$\n",
        "```python\n",
        "attention = ScaledDotProductAttention()\n",
        "attention_value = attention(q, k, v, mask=None)\n",
        "```"
      ],
      "metadata": {
        "id": "1c9YUo0mn-t2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# refer to Section 3.2.1 and Fig 2 (left) in the paper\n",
        "class ScaledDotProductAttention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self,q,k,v,mask=None):\n",
        "        # compute attention value based on transformed query, key, value where mask is given conditionally\n",
        "        \"\"\"\n",
        "        q, k, v = transformed query, key, value\n",
        "        q.shape, k.shape, v.shpae = [batch_size, num_head, seq_len, d=d_model/num_head]\n",
        "        mask = masking matrix, if the index has value False, kill the value; else, leave the value\n",
        "        \"\"\"\n",
        "        k_t =  torch.transpose(k, -1, -2) # [batch_size, num_head, d, seq_len]. k^T\n",
        "\n",
        "        numerator = torch.matmul(q, k_t)\n",
        "        denominator = np.sqrt(q.shape[-1])\n",
        "\n",
        "        attention_value = numerator/denominator\n",
        "\n",
        "        if mask != None:\n",
        "          # if the index has value False, kill the value; else, leave the value\n",
        "          # 논문에서는 -inf라서 그대로 따름\n",
        "          attention_value = attention_value.masked_fill(mask==0, -1e10)\n",
        "\n",
        "        attention_value = self.softmax(attention_value)\n",
        "        attention_value = torch.matmul(attention_value,v)\n",
        "\n",
        "        return attention_value"
      ],
      "metadata": {
        "id": "Onq2dngLoD-u"
      },
      "execution_count": 619,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **idea**"
      ],
      "metadata": {
        "id": "IeXo-hitgJFk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp_mask=torch.tensor([[True, False, True], [False, True, False]], dtype=torch.bool)\n",
        "temp_x = torch.tensor([[1,2,3],[4,5,6]], dtype = torch.float)\n",
        "\n",
        "temp_ans = torch.tensor([[1,0, 3],[0, 5, 0]], dtype=torch.float)\n",
        "temp_ans"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEiAImJ2fN7s",
        "outputId": "57470085-f624-4de0-e4bb-e2606c110adb"
      },
      "execution_count": 620,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 3.],\n",
              "        [0., 5., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 620
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp_x[temp_mask]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKril4xLfef5",
        "outputId": "031a3ae1-0725-408f-daab-8cdc84147873"
      },
      "execution_count": 621,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 3., 5.])"
            ]
          },
          "metadata": {},
          "execution_count": 621
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.mul(temp_mask, temp_x) # elementwise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsYzxlBFhRla",
        "outputId": "f385c0df-8900-4177-c87d-860cdd33922c"
      },
      "execution_count": 622,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 3.],\n",
              "        [0., 5., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 622
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Multi Head Attention**\n",
        "$$MultiHead(Q, K, V) = Concat(head_1, ... , head_h)W^{O}$$\n",
        "\n",
        "where $  head_i = Attention(QW^{Q}_{i}, QW^{K}_{i}, QW^{V}_{i})$\n",
        "\n",
        "```python\n",
        "multiheadattention = MultiHeadAttention(d_model, num_head)\n",
        "output = multiheadattention(q, k, v, mask=None)\n",
        "```"
      ],
      "metadata": {
        "id": "sJBlibJSoGRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# refer to Section 3.2.2 and Fig 2 (right) in the paper\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self,d_model=16,num_head=4):\n",
        "        super().__init__()\n",
        "        # fill out the rest\n",
        "        assert d_model % num_head == 0, \"check if d_model is divisible by num_head\"\n",
        "\n",
        "        # forward에서 필요한 parameter\n",
        "        self.d_model = d_model\n",
        "        self.num_head = num_head # head 개수 : h\n",
        "        self.d = d_model//num_head # d_k = d_v = d_model/h\n",
        "\n",
        "        # attention\n",
        "        self.attention = ScaledDotProductAttention()\n",
        "\n",
        "        # W_i : learnable\n",
        "        self.w_q = nn.Linear(self.d_model, self.d_model)\n",
        "        self.w_k = nn.Linear(self.d_model, self.d_model)\n",
        "        self.w_v = nn.Linear(self.d_model, self.d_model)\n",
        "\n",
        "        self.w_o = nn.Linear(self.d*self.num_head, self.d_model)\n",
        "\n",
        "    def forward(self,q,k,v,mask=None):\n",
        "        # fill out here\n",
        "        # compute multi-head attention value\n",
        "        # here, query, key, value are pre-transformed, so you need to transfrom them in this module\n",
        "        \"\"\"\n",
        "        q, k, v = pre-transformed query, key, value\n",
        "        q.shape, k.shape, v.shpae = [batch_size, seq_len, d_model]\n",
        "        mask = masking matrix, if the index has value False, kill the value; else, leave the value\n",
        "        \"\"\"\n",
        "        batch_size = q.shape[0]\n",
        "\n",
        "        QW = self.w_q(q) # [batch_size, seq_len, d_model]\n",
        "        KW = self.w_k(k)\n",
        "        VW = self.w_v(v)\n",
        "\n",
        "        '''\n",
        "        Note that\n",
        "\n",
        "        ScaledDotProductAttention의 input shape : [batch_size, num_head, seq_len, d]\n",
        "\n",
        "        현재 : [batch_size, seq_len, d_model]\n",
        "        reshape -> [batch_size, seq_len, num_head, d]\n",
        "        transpose(1,2) -> [batch_size, num_head, seq_len, d]\n",
        "\n",
        "        Colab에서 view()도 비슷한 기능이라고 추천하는데 안 써봐서 reshape 씀.\n",
        "        '''\n",
        "        QW = QW.reshape((batch_size, -1, self.num_head, self.d)).transpose(1,2)\n",
        "        KW = KW.reshape((batch_size, -1, self.num_head, self.d)).transpose(1,2)\n",
        "        VW = VW.reshape((batch_size, -1, self.num_head, self.d)).transpose(1,2)\n",
        "\n",
        "        head = self.attention(q=QW, k=KW, v=VW, mask=mask)\n",
        "        con_head = head.transpose(1,2).reshape(batch_size, -1, self.d_model) # -> [batch_size, -1 ,d_model]\n",
        "\n",
        "        output = self.w_o(con_head)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "-JD0KXDtoO7M"
      },
      "execution_count": 623,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kYzV3Sh_FgUf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Idea**"
      ],
      "metadata": {
        "id": "hdljDJlGp0kl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp=torch.arange(0, 120).reshape((4,5,6))\n",
        "temp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ijc9zpmBn15N",
        "outputId": "0c81cb1a-6456-4815-ce54-f390ba5b5176"
      },
      "execution_count": 624,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[  0,   1,   2,   3,   4,   5],\n",
              "         [  6,   7,   8,   9,  10,  11],\n",
              "         [ 12,  13,  14,  15,  16,  17],\n",
              "         [ 18,  19,  20,  21,  22,  23],\n",
              "         [ 24,  25,  26,  27,  28,  29]],\n",
              "\n",
              "        [[ 30,  31,  32,  33,  34,  35],\n",
              "         [ 36,  37,  38,  39,  40,  41],\n",
              "         [ 42,  43,  44,  45,  46,  47],\n",
              "         [ 48,  49,  50,  51,  52,  53],\n",
              "         [ 54,  55,  56,  57,  58,  59]],\n",
              "\n",
              "        [[ 60,  61,  62,  63,  64,  65],\n",
              "         [ 66,  67,  68,  69,  70,  71],\n",
              "         [ 72,  73,  74,  75,  76,  77],\n",
              "         [ 78,  79,  80,  81,  82,  83],\n",
              "         [ 84,  85,  86,  87,  88,  89]],\n",
              "\n",
              "        [[ 90,  91,  92,  93,  94,  95],\n",
              "         [ 96,  97,  98,  99, 100, 101],\n",
              "         [102, 103, 104, 105, 106, 107],\n",
              "         [108, 109, 110, 111, 112, 113],\n",
              "         [114, 115, 116, 117, 118, 119]]])"
            ]
          },
          "metadata": {},
          "execution_count": 624
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp.reshape((4,-1,2,3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrNFVUZFplaz",
        "outputId": "40d2e8cd-316f-47ea-8610-ae1210c5759f"
      },
      "execution_count": 625,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[  0,   1,   2],\n",
              "          [  3,   4,   5]],\n",
              "\n",
              "         [[  6,   7,   8],\n",
              "          [  9,  10,  11]],\n",
              "\n",
              "         [[ 12,  13,  14],\n",
              "          [ 15,  16,  17]],\n",
              "\n",
              "         [[ 18,  19,  20],\n",
              "          [ 21,  22,  23]],\n",
              "\n",
              "         [[ 24,  25,  26],\n",
              "          [ 27,  28,  29]]],\n",
              "\n",
              "\n",
              "        [[[ 30,  31,  32],\n",
              "          [ 33,  34,  35]],\n",
              "\n",
              "         [[ 36,  37,  38],\n",
              "          [ 39,  40,  41]],\n",
              "\n",
              "         [[ 42,  43,  44],\n",
              "          [ 45,  46,  47]],\n",
              "\n",
              "         [[ 48,  49,  50],\n",
              "          [ 51,  52,  53]],\n",
              "\n",
              "         [[ 54,  55,  56],\n",
              "          [ 57,  58,  59]]],\n",
              "\n",
              "\n",
              "        [[[ 60,  61,  62],\n",
              "          [ 63,  64,  65]],\n",
              "\n",
              "         [[ 66,  67,  68],\n",
              "          [ 69,  70,  71]],\n",
              "\n",
              "         [[ 72,  73,  74],\n",
              "          [ 75,  76,  77]],\n",
              "\n",
              "         [[ 78,  79,  80],\n",
              "          [ 81,  82,  83]],\n",
              "\n",
              "         [[ 84,  85,  86],\n",
              "          [ 87,  88,  89]]],\n",
              "\n",
              "\n",
              "        [[[ 90,  91,  92],\n",
              "          [ 93,  94,  95]],\n",
              "\n",
              "         [[ 96,  97,  98],\n",
              "          [ 99, 100, 101]],\n",
              "\n",
              "         [[102, 103, 104],\n",
              "          [105, 106, 107]],\n",
              "\n",
              "         [[108, 109, 110],\n",
              "          [111, 112, 113]],\n",
              "\n",
              "         [[114, 115, 116],\n",
              "          [117, 118, 119]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 625
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **PositionwiseFeedForwardNetwork**\n",
        "```python\n",
        "ffn = PositionwiseFeedForwardNetwork(d_model, num_head)\n",
        "output = ffn(x)\n",
        "```"
      ],
      "metadata": {
        "id": "wkhuFLZkoTeV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# refer to Section 3.3 in the paper\n",
        "class PositionwiseFeedForwardNetwork(nn.Module):\n",
        "    def __init__(self,d_model=16,d_ff=32):\n",
        "        super().__init__()\n",
        "\n",
        "        self.linear1 = nn.Linear(d_model,d_ff) # W1\n",
        "        self.linear2 = nn.Linear(d_ff, d_model) # W2\n",
        "        self.relu = nn.ReLU()  # max(0, xW1 + b1) : ReLU\n",
        "\n",
        "    def forward(self,x):\n",
        "        output = self.linear1(x)\n",
        "        output = self.relu(output)\n",
        "        output = self.linear2(output)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "suaqHOhGoXcA"
      },
      "execution_count": 626,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Masking**\n",
        "```python\n",
        "masking=Masking(device)\n",
        "mask=masking(x)\n",
        "```\n",
        "[Masking](https://data-science-blog.com/blog/2021/04/22/positional-encoding-residual-connections-padding-masks-all-the-details-of-transformer-model/)\n",
        "- masking : upper triangular 값이 False이면 됨\n",
        "- padding : 이미지 사이즈 다 똑같아서 안 해도 될 것 같음"
      ],
      "metadata": {
        "id": "nKLxEC8AoYr6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Masking(nn.Module):\n",
        "    def __init__(self,device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self,x):\n",
        "        \"\"\"\n",
        "        x.shape = [batch_size, seq_len, data_dim]\n",
        "        \"\"\"\n",
        "        seq_len = x.shape[1]\n",
        "        mask = torch.triu(torch.ones(seq_len, seq_len, dtype=torch.bool, device=self.device), diagonal=1)\n",
        "\n",
        "        return mask"
      ],
      "metadata": {
        "id": "iIIigiv1od-J"
      },
      "execution_count": 627,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Trial**"
      ],
      "metadata": {
        "id": "vsGwUTs3O40a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.triu(torch.ones(4, 4, dtype=torch.bool), diagonal=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j993WWkwPDHW",
        "outputId": "aefe9f4f-8b8f-4341-dd2b-34382f56b1cf"
      },
      "execution_count": 628,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False,  True,  True,  True],\n",
              "        [False, False,  True,  True],\n",
              "        [False, False, False,  True],\n",
              "        [False, False, False, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 628
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Layer Normalization**\n",
        "```python\n",
        "norm = LayerNormalization(d_model, eps)\n",
        "normed = norm(x)\n",
        "```\n",
        "[Pytorch LayerNorm Document](https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html)"
      ],
      "metadata": {
        "id": "lOo3enKnofCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# do not use torch.nn.LayerNorm\n",
        "class LayerNormalization(nn.Module):\n",
        "    def __init__(self, d_model=16, eps=1e-5):\n",
        "        super().__init__()\n",
        "        # fill out here\n",
        "        self.eps = eps # epsilon 이겠지?\n",
        "\n",
        "        # gamma, beta : learnable parameter. 출처 : torch document\n",
        "        # nn.Parameter(data, requires_grad=True) : default\n",
        "        self.gamma = nn.Parameter(torch.ones(d_model)) # torch document 는 1로 initialize...\n",
        "        self.beta = nn.Parameter(torch.zeros(d_model)) # torch document 는 0으로 initialize...\n",
        "\n",
        "    def forward(self,x):\n",
        "        # fill out here\n",
        "        numerator = x-torch.mean(x)\n",
        "        denominator = torch.sqrt(torch.var(x, unbiased=False) + self.eps)\n",
        "        normed = numerator/denominator\n",
        "        normed = normed*self.gamma + self.beta\n",
        "\n",
        "        return normed"
      ],
      "metadata": {
        "id": "UK-sk73UorDq"
      },
      "execution_count": 629,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Layerwise Encoder&Decoder**"
      ],
      "metadata": {
        "id": "CAL6MuaJor6Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 630,
      "metadata": {
        "id": "nR0X5r6xYT_4"
      },
      "outputs": [],
      "source": [
        "# refer to Section 3.1 and Figure 1 in the paper\n",
        "# this is a single encoder block consists of the following\n",
        "# multi-head attention(O), positionwise feed forward network(O), residual connections(O), layer normalizations(O)\n",
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self,d_model=16,num_head=4,d_ff=32, drop_prob=0.1):\n",
        "        super().__init__()\n",
        "        self.multiattention = MultiHeadAttention(d_model=d_model, num_head=num_head) # multi-head attention\n",
        "        self.feedforward = PositionwiseFeedForwardNetwork(d_model=d_model, d_ff=d_ff) # positionwise feed forward network\n",
        "\n",
        "        self.dropout = nn.Dropout(p=drop_prob) # residual Dropout\n",
        "\n",
        "        # layer normalizations, eps : 입력값 없으므로 default 값 적용\n",
        "        self.norm1 = LayerNormalization(d_model=d_model)\n",
        "        self.norm2 = LayerNormalization(d_model=d_model)\n",
        "\n",
        "    def forward(self,enc):\n",
        "        # 2-sub layers : Multi Head Attention+Add&Norm, Feed Forward+Add&Norm\n",
        "        residual = enc\n",
        "        ##\n",
        "        output = self.multiattention(q=enc, k=enc, v=enc, mask=None) # Q=x, K=x, V=x\n",
        "        output = self.norm1(self.dropout(output) + residual)  # Add & Norm\n",
        "        residual = output\n",
        "        ##\n",
        "        output = self.feedforward(output)\n",
        "        output = self.norm2(self.dropout(output)+residual) # Add & Norm\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# refer to Section 3.1 and Figure 1 in the paper\n",
        "# this is a single decoder block consists of the following\n",
        "# masked multi-head attention(O), multi-head attention(O), positionwise feed forward network(O), residual connections(O), layer normalizations(O)\n",
        "class DecoderLayer(nn.Module):\n",
        "\n",
        "    def __init__(self,d_model=16,num_head=4,d_ff=32,drop_prob=0.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.multiattention1 = MultiHeadAttention(d_model=d_model, num_head=num_head) # masked\n",
        "        self.multiattention2 = MultiHeadAttention(d_model=d_model, num_head=num_head)\n",
        "\n",
        "        self.feedforward = PositionwiseFeedForwardNetwork(d_model=d_model, d_ff=d_ff)\n",
        "\n",
        "        self.norm1 = LayerNormalization(d_model=d_model)\n",
        "        self.norm2 = LayerNormalization(d_model=d_model)\n",
        "        self.norm3 = LayerNormalization(d_model=d_model)\n",
        "\n",
        "        self.dropout = nn.Dropout(p=drop_prob)\n",
        "\n",
        "    def forward(self,enc_output,dec,dec_mask):\n",
        "        # 3-sub layers\n",
        "        residual = dec\n",
        "        ## masked multi-head attention\n",
        "        output = self.multiattention1(q=dec, k=dec, v=dec, mask=dec_mask)\n",
        "        output = self.norm1(self.dropout(output)+residual) # Add & Norm\n",
        "        residual = output\n",
        "        ## multi-head attention\n",
        "        output = self.multiattention2(q=output, k=enc_output, v=enc_output, mask=None)\n",
        "        output = self.norm2(self.dropout(output)+residual) # Add & Norm\n",
        "        residual = output\n",
        "        ## positionwise feed forward network\n",
        "        output = self.feedforward(output) # Feed Forward\n",
        "        output = self.norm3(self.dropout(output)+residual) # Add & Norm\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "NOqwZa21pCYT"
      },
      "execution_count": 631,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Encoder&Decoder**"
      ],
      "metadata": {
        "id": "0qiUjePQpJud"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **input projection 관련 정리**\n",
        "```python\n",
        "\"\"\"\n",
        "in this homework, encoder inputs are not tokens, it is already embeddings in the input dimension\n",
        "hence, you don't have to set input embedding layer\n",
        "instead, you have to transform the input into the hidden dimension with single linear transformation\n",
        "\"\"\"\n",
        "```"
      ],
      "metadata": {
        "id": "dSbaprIROaz-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[사이버캠퍼스 공지] 과제 출제"
      ],
      "metadata": {
        "id": "SjGLzRpLOitW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이번 과제에서는 여러 여건상 cifar 데이터를 기반으로 3 * 32 * 32 사이즈 이미지의 윗부분을 sequential하게 보고 나머지 아랫부분을 sequential 하게 맞추는 형태로 연습을 진행합니다.\n",
        "\n",
        "구체적으로 설명드리자면 0~1 사이의 값을 갖는 (r,g,b) 형태로 된 하나의 pixel이 있다면, 이미지를 1024(=32*32) 길이를 가진 pixel sequence로 변환을 합니다.\n",
        "\n",
        "그런 다음 앞의 512개의 (r,g,b)-sequence를 input으로 넣어서 뒤의 512개의 (r,g,b)-sequence를 output으로 sequential 3-dimensional binary prediction을 하는 것이 전반적인 구조입니다.\n",
        "\n",
        "모든 구현은 Transformer 논문 (Attention is All You Need) 기반으로 하시면 됩니다.\n",
        "\n",
        "딱 한가지 다른 것은, 기존의 Transformer는 input으로 들어가는 값이 sequential of word index, one-hot vector 등의 형태인데, 우리 과제에서는 sequential of 0~1 (r,g,b)-vector 형태입니다.\n",
        "\n",
        "따라서, input embedding을 (우리가 아직 수업에서 다루지 않은) embedding lookup이 아닌, 여러분이 통상적으로 사용했던 linear transformation으로 만들면 되겠습니다. (즉, 3 dim (r,g,b)-vector를 d_model dimensional vector로 linear layer를 통해 변환하면 됩니다.)\n",
        "\n",
        "나머지 코드는 제가 모두 작성해뒀으니 다른 부분은 건들 필요가 없긴 한데, 당연히 이 부분도 debugging을 하실 때 수정하시는 것은 상관이 없습니다.\n",
        "\n",
        "특히, 제공한 코드 파일의 line 261은 일단 주석 처리를 해두고 num_layer, d_model, num_head, d_ff 등의 hyper-parameter 값을 낮춰서 먼저 코드가 돌아가도록 debugging 하시는 것을 추천드립니다.\n",
        "\n",
        "마지막으로 num_epoch은 100으로 설정해두었는데, 모델 학습이 아닌 모델 구현이 목표인 만큼 loss는 적당히 감소하는지 정도만 확인하시면 되고 전체 epoch에 대해서 학습하실 필요는 없습니다"
      ],
      "metadata": {
        "id": "6mqsCR5QOoVY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Code**"
      ],
      "metadata": {
        "id": "bI3xJofZOgMA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# refer to Section 3.1 and Figure 1 in the paper\n",
        "# this is a whole encoder, i.e., the left side of Figure 1, consists of the following as well\n",
        "# input embedding, positional encoding\n",
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self,device,input_dim=3,num_layer=3,max_len=512,d_model=16,num_head=4,d_ff=32,drop_prob=.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.input_projection = nn.Linear(input_dim, d_model)\n",
        "\n",
        "        self.pos_encoding = PositionalEncoding(device=device, max_len=max_len, d_model=d_model)\n",
        "\n",
        "        # self.encoder_N = nn.Sequential([EncoderLayer(d_model, num_head, d_ff, drop_prob) for i in range(num_layer)])\\\n",
        "        self.encoder_N = nn.ModuleList([EncoderLayer(d_model=d_model, num_head=num_head, d_ff=d_ff, drop_prob=drop_prob) for i in range(num_layer)])\n",
        "\n",
        "    def forward(self,x):\n",
        "        # fill out here\n",
        "        seq_len = x.shape[1]\n",
        "\n",
        "        input_embedding = self.input_projection(x)\n",
        "        pos_embedding = self.pos_encoding(input_embedding)\n",
        "\n",
        "        hidden = input_embedding + pos_embedding\n",
        "\n",
        "        for encoderlayer in self.encoder_N:\n",
        "          hidden = encoderlayer(hidden)\n",
        "\n",
        "        return hidden"
      ],
      "metadata": {
        "id": "H83Yd4oEo_KN"
      },
      "execution_count": 632,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# refer to Section 3.1 and Figure 1 in the paper\n",
        "# this is a whole decoder, i.e., the left side of Figure 1, consists of the following as well\n",
        "# input embedding, positional encoding, linear classifier\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self,device,input_dim=3,num_layer=3,max_len=512,d_model=16,num_head=4,d_ff=32,drop_prob=.1):\n",
        "        super().__init__()\n",
        "        self.input_projection = nn.Linear(input_dim, d_model)\n",
        "\n",
        "        self.pos_encoding = PositionalEncoding(device, max_len,d_model)\n",
        "\n",
        "        # self.decoder_N = nn.Sequential([DecoderLayer(d_model, num_head, d_ff, drop_prob) for i in range(num_layer)])\n",
        "        self.decoder_N = nn.ModuleList([DecoderLayer(d_model, num_head, d_ff, drop_prob) for i in range(num_layer)])\n",
        "\n",
        "        self.classifier = nn.Linear(d_model, input_dim) # linear classifier\n",
        "\n",
        "    def forward(self,enc_output,y,y_mask):\n",
        "        # fill out here\n",
        "        output_embedding = self.input_projection(y)\n",
        "        pos_embedding = self.pos_encoding(output_embedding)\n",
        "\n",
        "        output = output_embedding + pos_embedding\n",
        "\n",
        "        for decoderlayer in self.decoder_N:\n",
        "          output = decoderlayer(enc_output, output, y_mask)\n",
        "\n",
        "        output = self.classifier(output)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "2dZvDTuZ54Xe"
      },
      "execution_count": 633,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **nn.Sequential과 nn.ModuleList**\n",
        "- `nn.Conv2d` 등과 같이`torch.nn` 아닌 내가 정의한 `class`에 대해서 `nn.Sequential`을 적용해도 되는가?\n",
        "- `nn.Sequential` : 계단식 구조, forward... -> 잘 모르겠음. training setting 단계에서 오류 발성\n",
        "- `nn.ModuleList` : 오류는 안 남...\n",
        "- [DL] PyTorch: nn.ModuleList, nn.ModuleDict, nn.Sequential](https://ds31x.tistory.com/266#google_vignette)"
      ],
      "metadata": {
        "id": "GCdiQncTz9W7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Transformer**"
      ],
      "metadata": {
        "id": "827gYspjo1zW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# refer to Section 3.1 and Figure 1 in the paper\n",
        "# sum up encoder and decoder\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, device, input_dim=3, num_layer=3, max_len=512, d_model=16, num_head=4, d_ff=32, drop_prob=.1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.masking = Masking(device)\n",
        "\n",
        "        self.encoder = Encoder(device=device,input_dim=input_dim,num_layer=num_layer,max_len=max_len,d_model=d_model,num_head=num_head,d_ff=d_ff,drop_prob=drop_prob)\n",
        "        self.decoder = Decoder(device=device,input_dim=input_dim,num_layer=num_layer,max_len=max_len,d_model=d_model,num_head=num_head,d_ff=d_ff,drop_prob=drop_prob)\n",
        "\n",
        "    def forward(self,x,y):\n",
        "        y_mask = self.masking(y)\n",
        "\n",
        "        enc_output = self.encoder(x)\n",
        "        dec_output = self.decoder(enc_output, y, y_mask)\n",
        "\n",
        "        return dec_output"
      ],
      "metadata": {
        "id": "teeMpId45bpz"
      },
      "execution_count": 634,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model Train Setting**"
      ],
      "metadata": {
        "id": "woBgB4KTlg6z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##########################################\n",
        "#### there is nothing to do from here ####\n",
        "##########################################"
      ],
      "metadata": {
        "id": "tJKQKOr2bTx7"
      },
      "execution_count": 635,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ScheduledOptimizer:\n",
        "    def __init__(self,optimizer,d_model=16,warmup_steps=4000):\n",
        "        self.optimizer = optimizer\n",
        "        self.d_model = d_model\n",
        "        self.warmup_steps = warmup_steps\n",
        "        self.step_num = 0\n",
        "\n",
        "    def zero_grad(self):\n",
        "        self.optimizer.zero_grad()\n",
        "\n",
        "    def update_parameter_and_learning_rate(self):\n",
        "        self.optimizer.step()\n",
        "        self.step_num += 1\n",
        "        self.lr = self.d_model**(-.5) * min(self.step_num**(-.5),self.step_num*self.warmup_steps**(-1.5))\n",
        "        for param_group in self.optimizer.param_groups:\n",
        "            param_group['lr'] = self.lr"
      ],
      "metadata": {
        "id": "xDW3t0IAbSbT"
      },
      "execution_count": 636,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Setting**"
      ],
      "metadata": {
        "id": "RvUNtrUynlSQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# modify num_layer, d_model, num_head, d_ff while debugging your code\n",
        "model = Transformer(device=device,input_dim=3,num_layer=3,max_len=512,d_model=16,num_head=4,d_ff=32,drop_prob=.1).to(device)\n",
        "loss = nn.BCEWithLogitsLoss(reduction=\"mean\")\n",
        "optimizer = torch.optim.Adam(model.parameters(),betas=(.9,.98),eps=1e-9)\n",
        "scheduled_optimizer = ScheduledOptimizer(optimizer,d_model=16)"
      ],
      "metadata": {
        "id": "_3fDkmxrnoCS"
      },
      "execution_count": 637,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Epoch 설정\n",
        "num_epoch = 1"
      ],
      "metadata": {
        "id": "cJzSmEysmGaU"
      },
      "execution_count": 606,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Train Model**"
      ],
      "metadata": {
        "id": "7DAaQSncl6v4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss_list, test_loss_list = list(), list()\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(\"num_param:\", total_params)"
      ],
      "metadata": {
        "id": "koK2XayWmCuc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ced8179-0501-47f1-8f2c-8da2b36f4dbb"
      },
      "execution_count": 638,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_param: 16883\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **학습 결과**"
      ],
      "metadata": {
        "id": "V-tjSzjBmve3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_epoch):\n",
        "    # train\n",
        "    model.train()\n",
        "\n",
        "    # initialize(epoch마다)\n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "\n",
        "    # 50000/100 : iterate 500\n",
        "    for batch_idx, (image, label) in enumerate(train_loader):\n",
        "        image = image.reshape(-1,3,1024).transpose(1,2) # image.shape : torch.Size([100, 3, 32, 32]) -> torch.Size([100, 1024, 3])\n",
        "        x, y = image[:,:512,:].to(device), image[:,512:,:].to(device) # Crop : 3 * 32 * 32 사이즈 이미지의 윗부분\n",
        "\n",
        "        y_ = torch.zeros([y.shape[0],1,3],requires_grad=False).to(device)\n",
        "        y_ = torch.cat([y_,y[:,:-1,:]],dim=1) # 맨 윗부분이 0\n",
        "        '''\n",
        "        y_[0]\n",
        "\n",
        "        tensor([[0.0000, 0.0000, 0.0000],\n",
        "        [0.3098, 0.2078, 0.1412],\n",
        "        [0.4549, 0.4157, 0.3843],\n",
        "        ...,\n",
        "        [0.4745, 0.2392, 0.1294],\n",
        "        [0.4706, 0.2353, 0.1294],\n",
        "        [0.4275, 0.1922, 0.0941]])\n",
        "        '''\n",
        "\n",
        "        logit = model.forward(x,y_)\n",
        "        cost = loss(logit, y)\n",
        "\n",
        "        total_loss += cost.item() * y.shape[0]* y.shape[1] * y.shape[2] # 100*512*3\n",
        "\n",
        "        scheduled_optimizer.zero_grad()\n",
        "        cost.backward()\n",
        "        scheduled_optimizer.update_parameter_and_learning_rate()\n",
        "\n",
        "    ave_loss = total_loss/len(train_data)\n",
        "    train_loss_list.append(ave_loss)\n",
        "\n",
        "    if i % 1 == 0:\n",
        "        print(\"\\nEpoch %d Train: %.3f with Learning Rate: %.5f\"%(i,ave_loss, scheduled_optimizer.lr))\n",
        "\n",
        "    ## test\n",
        "    model.eval()\n",
        "\n",
        "    total_loss = 0\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (image, label) in enumerate(test_loader):\n",
        "\n",
        "            image = image.reshape(-1,3,1024).transpose(1,2)\n",
        "            x, y = image[:,:512,:].to(device), image[:,512:,:].to(device)\n",
        "\n",
        "            y_ = torch.zeros([y.shape[0],1,3],requires_grad=False).to(device)\n",
        "            y_ = torch.cat([y_,y[:,:-1,:]],dim=1)\n",
        "\n",
        "            logit = model.forward(x,y_)\n",
        "            cost = loss(logit, y)\n",
        "\n",
        "            total_loss += cost.item() * y.shape[0] * y.shape[1] * y.shape[2]\n",
        "\n",
        "    ave_loss = total_loss/len(test_data)\n",
        "    test_loss_list.append(ave_loss)\n",
        "\n",
        "    if i % 1 == 0:\n",
        "        print(\"Epoch %d Test: %.3f\"%(i,ave_loss))"
      ],
      "metadata": {
        "id": "kOBuZW2nlwBu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "001192d7-105f-41f8-c555-d958eb8b10af"
      },
      "execution_count": 608,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 0 Train: 849.392 with Learning Rate: 0.00150\n",
            "Epoch 0 Test: 837.608\n",
            "\n",
            "Epoch 1 Train: 832.327 with Learning Rate: 0.00200\n",
            "Epoch 1 Test: 818.084\n",
            "\n",
            "Epoch 2 Train: 820.856 with Learning Rate: 0.00249\n",
            "Epoch 2 Test: 814.263\n",
            "\n",
            "Epoch 3 Train: 817.503 with Learning Rate: 0.00298\n",
            "Epoch 3 Test: 813.269\n",
            "\n",
            "Epoch 4 Train: 816.071 with Learning Rate: 0.00348\n",
            "Epoch 4 Test: 812.834\n",
            "\n",
            "Epoch 5 Train: 815.439 with Learning Rate: 0.00394\n",
            "Epoch 5 Test: 813.526\n",
            "\n",
            "Epoch 6 Train: 814.959 with Learning Rate: 0.00372\n",
            "Epoch 6 Test: 812.518\n",
            "\n",
            "Epoch 7 Train: 814.536 with Learning Rate: 0.00353\n",
            "Epoch 7 Test: 812.181\n",
            "\n",
            "Epoch 8 Train: 814.291 with Learning Rate: 0.00337\n",
            "Epoch 8 Test: 812.397\n",
            "\n",
            "Epoch 9 Train: 814.086 with Learning Rate: 0.00322\n",
            "Epoch 9 Test: 811.761\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Reference**\n",
        "- [Jonas Gehring, Michael Auli, David Grangier, Denis Yarats, and Yann N. Dauphin. Convolu\n",
        "tional sequence to sequence learning. arXiv preprint arXiv:1705.03122v2, 2017.](https://arxiv.org/pdf/1705.03122)\n",
        "- [Pytorch LayerNorm Document](https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html)\n",
        "- [Positional encoding, residual connections, padding masks: covering the rest of Transformer components](https://data-science-blog.com/blog/2021/04/22/positional-encoding-residual-connections-padding-masks-all-the-details-of-transformer-model/)\n",
        "\n"
      ],
      "metadata": {
        "id": "OYQ9Ox8FNHBT"
      }
    }
  ]
}